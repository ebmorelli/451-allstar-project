{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, RepeatedStratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from hyperopt import Trials, STATUS_OK, tpe, hp, fmin\n",
    "import hyperopt.pyll.stochastic\n",
    "import optuna\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing\n",
    "df = pd.read_csv(\"master_data.csv\")\n",
    "df['RS%'] = df['RS%'].str.rstrip('%').astype('float') / 100.0\n",
    "df['SB%'] = df['SB%'].str.rstrip('%').astype('float') / 100.0\n",
    "df = df.dropna()\n",
    "train, test = train_test_split(df, random_state=123)\n",
    "xcols = [\"Age\", \"G\", \"R\", \"H\", \"HR\", \"RBI\", \"SB\", \"SO\", \"BA\", \"SLG\", \"OPS\", \"Value Ranking\", \"WPA\", \"RS%\", \"SB%\", \"ISO\"]\n",
    "xcols_alt = [\"R\", \"H\", \"HR\", \"RBI\", \"SO\", \"OPS\", \"Value Ranking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 41\n",
      "2015 40\n",
      "2016 37\n",
      "2017 37\n",
      "2018 36\n",
      "2019 38\n",
      "2021 36\n"
     ]
    }
   ],
   "source": [
    "for i in [2014, 2015, 2016, 2017, 2018, 2019, 2021]:\n",
    "    print(i, df.loc[df['Year'] == i][\"allstars\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 93.086%\n",
      "Valid Accuracy: 91.907%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Reg\n",
    "model = Pipeline([\n",
    "    (\"std\", StandardScaler()),\n",
    "    (\"logr\", LogisticRegression(random_state=123))\n",
    "])\n",
    "model.fit(train[xcols], train[\"allstars\"])\n",
    "model.score(test[xcols], test[\"allstars\"])\n",
    "\n",
    "print(f\"Train Accuracy: {model.score(train[xcols], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {model.score(test[xcols], test['allstars'])*100:0.3f}%\")\n",
    "pd.Series(model[\"logr\"].coef_.reshape(-1), index=xcols).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "90 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.9304009  0.92994428 0.90749235 0.91207113        nan 0.92765699\n",
      " 0.92811571 0.90749235 0.91207113 0.92719618        nan        nan\n",
      " 0.90795107        nan 0.9276528         nan        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'penalty': 'none', 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuning hyperparametres for logistic regression\n",
    "\n",
    "model = LogisticRegression(random_state=123)\n",
    "\n",
    "params =  {\n",
    "    'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'saga', 'sag', 'liblinear']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model,\n",
    "                    param_grid=params,\n",
    "                    cv=10,\n",
    "                    n_jobs=1,\n",
    "                    verbose=1)\n",
    "\n",
    "grid.fit(train[xcols_alt], train['allstars'])\n",
    "\n",
    "grid.best_params_\n",
    "\n",
    "# Decision Tree with grid search params w alt features\n",
    "\n",
    "#model = model = Pipeline([\n",
    "#    (\"std\", StandardScaler()),\n",
    "#    (\"logr\", LogisticRegression(penalty)\n",
    "#])\n",
    "#model.fit(train[xcols_alt], train[\"allstars\"])\n",
    "#print(f\"Train Accuracy: {model.score(train[xcols_alt], train['allstars'])*100:0.3f}%\")\n",
    "#print(f\"Valid Accuracy: {model.score(test[xcols_alt], test['allstars'])*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 92.995%\n",
      "Valid Accuracy: 91.907%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAE2CAYAAAB87RlzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZz0lEQVR4nO3debhkVXnv8e8LiCLSQqQRFJsWEA0CCh4cwGhAYlSc5Srmqjh2kis4XS8OxGiCuRIHiDegplVwCIrcIIPihIo4gjZTI6OIjXNsUIwKiMCbP9Y+dHE4Q9Xe+1i16O/nec7Ttfeu89bqqjq/vWrttXdFZiJJqtcG426AJKkbg1ySKmeQS1LlDHJJqpxBLkmVM8glqXIbjeNBt9xyy1y+fPk4HlqSqnXuuedek5lLZ67vJcgjYnPgA8AuQAIvzsxvzXX/5cuXs2rVqj4eWpLWGxFx9Wzr++qRvxv4XGYeEBEbA3fvqa4kaQGdgzwilgCPAV4IkJk3ATd1rStJGk4fBzu3B9YCx0XE+RHxgYjYtIe6kqQh9BHkGwF7AO/NzN2B3wGvn3mniFgREasiYtXatWt7eFhJEvQT5D8GfpyZ5zTL/0EJ9tvJzJWZOZWZU0uX3uGgqySppc5Bnpk/B34UEQ9sVj0OuKRrXUnScPqatXIIcHwzY+Uq4EU91ZUkLaCXIM/MC4CpPmpJkkYzljM7JcHy158+1P3WHLH/IrdEtfNaK5JUOYNckipnkEtS5QxySaqcQS5JlTPIJalyBrkkVc4gl6TKGeSSVDmDXJIqZ5BLUuUMckmqnEEuSZUzyCWpcga5JFXOIJekyhnkklQ5g1ySKmeQS1LlDHJJqpxBLkmVM8glqXIGuSRVziCXpMoZ5JJUud6CPCI2jIjzI+LTfdWUJC2szx75K4FLe6wnSRpCL0EeEdsC+wMf6KOeJGl4ffXI/wU4FLi1p3qSpCF1DvKIeDLwi8w8d4H7rYiIVRGxau3atV0fVpLU6KNHvjfw1IhYA5wA7BsR/z7zTpm5MjOnMnNq6dKlPTysJAl6CPLMfENmbpuZy4EDgS9n5vM6t0ySNBTnkUtS5Tbqs1hmfgX4Sp81JUnzs0cuSZUzyCWpcga5JFXOIJekyhnkklQ5g1ySKmeQS1LlDHJJqpxBLkmVM8glqXIGuSRVziCXpMoZ5JJUOYNckirX62VsJY3P8tefPvR91xyx/yK2RH9s9sglqXL2yCfAsD0pe1GSZmOPXJIqZ5BLUuUMckmqnEEuSZUzyCWpcga5JFXOIJekyhnkklS5zkEeEfeLiDMj4tKIuDgiXtlHwyRJw+njzM6bgf+dmedFxGbAuRFxRmZe0kNtSdICOvfIM/NnmXlec/s3wKXAfbvWlSQNp9cx8ohYDuwOnNNnXUnS3HoL8oi4B3AS8KrM/K9Ztq+IiFURsWrt2rV9Pawkrfd6CfKIuAslxI/PzE/Odp/MXJmZU5k5tXTp0j4eVpJEP7NWAvggcGlmHtm9SZKkUfTRI98beD6wb0Rc0Pw8qYe6kqQhdJ5+mJlfB6KHtkiSWvDMTkmqnEEuSZUzyCWpcga5JFXOIJekyhnkklQ5g1ySKmeQS1LlDHJJqpxBLkmVM8glqXIGuSRVro/v7NQEWv7604e635oj9l/klkhabPbIJalyBrkkVc4gl6TKGeSSVDmDXJIqZ5BLUuUMckmqnEEuSZUzyCWpcp7ZKal6w57JDHfOs5kNcg3N0/6lyeTQiiRVziCXpMr1EuQR8YSIuDwiroyI1/dRU5I0nM5BHhEbAscATwR2Bp4bETt3rStJGk4fBzsfDlyZmVcBRMQJwNOAS3qorTs5D6BqUtU0EyYys1uBiAOAJ2TmS5vl5wOPyMyDZ9xvBbACYNmyZQ+7+uqrb1dnMZ60cdYc9wu7PluM12h9fd1r+busRdf/e0Scm5lTM9f30SOPWdbdYe+QmSuBlQBTU1Pd9h6SqnVnC+dJ0EeQ/xi438DytsBPRy3iiytNHv8u69DHrJXvAA+IiPtHxMbAgcBpPdSVJA2hc488M2+OiIOBzwMbAsdm5sWdWya1ZC9S65teTtHPzM8An+mjliRpNJ7ZKUmVM8glqXIGuSRVziCXpMoZ5JJUOYNckipnkEtS5fyqtxF5somkSWOPXJIqd6fukdt7lrQ+sEcuSZUzyCWpcga5JFXOIJekyhnkklQ5g1ySKmeQS1LlDHJJqpxBLkmVM8glqXIGuSRVziCXpMoZ5JJUOYNckipnkEtS5ToFeUS8IyIui4jVEXFyRGzeU7skSUPq2iM/A9glM3cDrgDe0L1JkqRRdAryzPxCZt7cLJ4NbNu9SZKkUfQ5Rv5i4LM91pMkDWHB7+yMiC8CW8+y6bDMPLW5z2HAzcDx89RZAawAWLZsWavGSpLuaMEgz8z95tseEQcBTwYel5k5T52VwEqAqampOe8nSRrNgkE+n4h4AvA64LGZeX0/TZIkjaLrGPnRwGbAGRFxQUS8r4c2SZJG0KlHnpk79tUQSVI7ntkpSZUzyCWpcga5JFXOIJekyhnkklQ5g1ySKmeQS1LlDHJJqpxBLkmVM8glqXIGuSRVziCXpMoZ5JJUOYNckipnkEtS5QxySaqcQS5JlTPIJalyBrkkVc4gl6TKGeSSVDmDXJIqZ5BLUuUMckmqnEEuSZXrJcgj4rURkRGxZR/1JEnD6xzkEXE/4C+AH3ZvjiRpVH30yI8CDgWyh1qSpBF1CvKIeCrwk8y8sKf2SJJGtNFCd4iILwJbz7LpMOCNwOOHeaCIWAGsAFi2bNkITZQkzWfBIM/M/WZbHxG7AvcHLowIgG2B8yLi4Zn581nqrARWAkxNTTkMI0k9WTDI55KZFwFbTS9HxBpgKjOv6aFdkqQhOY9ckirXukc+U2Yu76uWJGl4vQW5dGe25oj9x90EaU4OrUhS5QxySaqcQS5JlTPIJalyBrkkVc4gl6TKGeSSVDmDXJIqZ5BLUuUMckmqnEEuSZUzyCWpcga5JFXOIJekyhnkklQ5g1ySKmeQS1LlDHJJqpxBLkmVM8glqXIGuSRVziCXpMoZ5JJUOYNckipnkEtS5TbqWiAiDgEOBm4GTs/MQzu3SpLuhNYcsf+i1O0U5BGxD/A0YLfM/H1EbNVPsyRJw+o6tPK3wBGZ+XuAzPxF9yZJkkbRNch3Av4sIs6JiLMiYs8+GiVJGt6CQysR8UVg61k2Hdb8/hbAI4E9gRMjYvvMzFnqrABWACxbtqxLmyVJAxYM8szcb65tEfG3wCeb4P52RNwKbAmsnaXOSmAlwNTU1B2CXpLUTtehlVOAfQEiYidgY+CajjUlSSPoOv3wWODYiPgucBNw0GzDKpKkxdMpyDPzJuB5PbVFktSCZ3ZKUuViHCMhEbEWuHqIu25J/2Pu1rSmNdePmjW0cdSa22Xm0pkrxxLkw4qIVZk5ZU1rWtOa4643yTUdWpGkyhnkklS5SQ/ylda0pjWtOSH1JrbmRI+RS5IWNuk9cknSAgxySapc528ImmQR8TRg28w8plk+B5ieg3loZv7H2BqnO4WIuB9wYGa+Y9xtWUwR8cxZVv8auMjvIRi/iQryiLg38H+B+2TmEyNiZ+BRmfnBliUPBQ4cWL4r5XK7mwLHAb0FeURsSPmDPr7F7/4rMOfBisx8RYc2bZGZ1zTLGwMvBF6dmX/aot6nFmjnU1u2cyPglszMJhgfAXw/M89vU2+g7j7AgyltviQzz+xSb6DulsD/AJ4L3Bc4uUWNBwM7ZOZpzfJRwD2bzUdn5nktat4d+ENm/qFZfiDwJODqzPzkqPVmeAnwKGD6Ofxz4Gxgp4j4x8z8aJfiEbED5fk8MDN36VKrqfcU4O8of/MrM/M9k1QzIu7PuvfmpZl5VafGZebE/ACfBZ4NXNgsb0TZ47et950Zy0cP3D67Zc0lwBuAo4HHAwEcQjlT9dSWNQ8a+FkzY/mgljUPpPSYfgqcBewD/JgSOnu0rPnY+X5a1nwZ8Evgh83tK4ATgMuB17WseV/gnOb/fSRwVHP728B9W9bcDHgB8DngKuBdwI87vDc/Bew1sHwJ8Czg+cApLWt+FXhAc3vH5nn9V+BLwNvatnWgvfceWL438EngT4Dvtqy5DfCq5nW5EXgzsGvLWg+ZsXxi87e5QdsMWaSaS5o6VzXP38nN7f8PLGn9+nR5cfv+mQ5e4PyBdRd0qHflPNu+37LmqcCHgL9uXpAzmpB4aE/Pwfk91fkusGNzew/g98Azxv0az9LOiylfTrIM+B2wZbP+7sDFLWueDLxwlvUvoP3O9obmdf4z1s32uqrD/3vVjOWzB25/vWXNiwZuHw4c09zeuG3wzFa7WY7pAB/1PUvZYX+ZstN+K7Ab8IOO7fs3yjS+rZvld1E+3b8V+PwE1fwQ8BZggxnP5d8DH2n9/+/y5PX9A3wFuBdwXrP8SOCsDvWOB142y/q/Bj7esubgH8uGwK+AzXp8Ds5bjDrAZT3UfABlSOpIYFvKJ6jfAhcCUy1rnj9w+8K5to1Y8/I22xao+WpKL/+7wBuBHToG+XxtvKJlzdUDt78BPH2u57ZF7fcAn2bdJ8XTmnWbAmeOWOsmyk5xamBd6+dyoMZDKB2tN1E6AvsBTwXuOik1ge+12bbQz0SNkQOvobxBdoiIb1AOTB7Qod6rgVMi4q+A6THHh1HGuJ7esuYfpm9k5i0R8YPM/E2HNi6WrSLiNQPL9xhczswjW9Q8DvgI5ePhOZSPxc+g9FKPoYxtj2qTiNid8nF144jYo1kfwN1a1IOyg72DiNhgrm0LycyjgKMiYnvKWO4pwH0i4nXAyZl5xYglfxoRj8jMc2a08ZGU4bA2VkfEO5vf3xH4QlNz85b1Br2cMvSzN+W1+QhwUpYE2mfEWvehHGM4sjkudiJwl64NzMwLgac1Y9mnAR/OjmP3i1AzurRnzqLNnmBiNAe+Hkj5D1+ezYGbjjX3pRxYgPJx/csdat1CGQKA0sZNgOub25mZS1rU/A3rDiLevak3Xb9tzTfPtz0z/6FFzQsy86HN7Sszc8fZto1Y80zK/336DT74hozMHDUkiIh/ofQUX5WZv2vWbUoZK78xWx48nuVxdgX+Cnh2Zu4w4u8+HPgE5aP2YCfjIOA5mfntFu3ZBHgl5Tt2j2tCiIjYi3JgtVOoLYaI2JZyPOe5lPf+yZn5xhZ1/obySTuBt1MmMvwvYH/grZn5tQmp+WHg+8DhORC+EfEmYKfMfP6oNWHCgtwpTpMtIs7LzD1m3p5teYSaDwd+lJk/a5YPovT81gBvycxftqh5F8pY5osoB6ET2A74MPDGLF+I0lkze+XabPlHFBFbAQcz0MmgjGv/Z4c27U4Z9rk4My9tW2eWus8E/hnYirLTbd3JaOo9nfKp4aLM/Hyz7oGUWSttOhmrM3O3ZmbWtzLzYc36LYA3ZeZr5q/wR6u5BPgg5bjVBZT35h6UnflLMvPXo9aEyQvy05ljihPQeYrT+iQi/t9829v0SiPieuBKyh/xDs1tmuXtM3PTFjXPA/bLzF9GxGMoM1YOAR4K/Glmjjy0FhF7UmboXEcJi32AJwOX0X7n8EjgCMpMkMOBj1KuI70B8ILM/NyoNed5rE9k5nNa/N7fU76x61zKMNfbMvP9PbXpSuApfewcIuI9lJ3XN4HHAZ/KzMM71vwssIryCXmbzPyfPbSz95oDtXcAdqb87Vycmd/vVG/CgvxTwEuneyTN+Nl7gZcCX80e5peuL5qe7bR/oEztuk1mfrhFze3m256Zw3xZyMyaF2bmQ5rbxwBrM/MtzXLb4ZrF2DmsohzkvCdlJsMTM/PsiHgQ5cD57qPWnOexfpiZy1r83sXAnpl5fUTcC/hcZu7ZU5u+kZl791Tru5Spfbc0c9+/Nt3b7VBzY+AvKcewzsjMW3po52LU3A64brrn3Zzr8HTKJ8ej235anLSDnctnfKz8BWXc6JcR0XmsfH0yGNQR8ao2wT1LzVmDevpkKIb71qeZNoyIjTLzZkrvbMXAtrbvzw0Het3PoZy8cRJwUkRc0LLmRpk5ffDwHzPzbIDMvCxiUY5ftXFjZl4PkJnXNgd3+7IqIj5BOcj7++mV2e5Eo5umQ7HZ6fTxBG5D6ez1FpCZeVPTK+/zZLUTKRMEfh0RD6XMH38bZXbMeyid1pFNWpB/LSI+TfnPQRkr/WpzoOq6sbWqfr187GrG915OOeHmNMoc+oOB11LG+0Y+qxX4OHBWRFxDmav9teaxdqQcH2ljMXYOtw7cvmHGtpGf34HZOXfYRPsZHDtExGmzLE+PZ7c687axhHIQ/vED65JyUsuoHhQRq5vb0bRz9UA7d2tRs/eAjIiXUY4L/DYiDgf+D2Use/eIODYz/7lFOzfJzOlZSc8Djs3MdzU73Qta1CttnbChlQCeCTy6WXUtZWzq5eNrVf3aHoicpc6plHnz36IE5BaUk01emZkXdKj7SEqP6gsDs0x2Au6R7U5VP4xyavo1lBON9mh6VDtSpo+NPEQwMFtpcKYSzfLdMnOk8F2k2TqPbW5uQpnzfytlhsQNAJl51qg1F0NEvBr4OuW9dIdP2i2H6FZP7wCaKZi3Zuah0wHZZufQDFU9mnJW76WU78u8phkO+k5mPnjeArPXvCgzd21unwe8YeBg7+qWO7HJ6pE3f2zfp3x8eTbwA+Ck8baqTjOnNEbEf01vov1sg+0H3oQfoAnK7DiPfnqYYsa6UedlD/7uP0XEl1i3c5h+HjagjJW3qdlq/vk8Xsc8s3Va1vwm8E/AiymXPAjKiVsfoozvjywiDs3Mt8cc1wNqc9Cc8onu3cCDgNVNu79BmRky8oHo6aYO3N6XchkNMvPWDiM3N2Xmr4BfRZlue01T8/qIaDvz6csRcSLwM0pH6MsAEbEN5USpViYiyJve1/Rc0msp82tb9UpUZOZmi1C2lpOhet85LIL3Uc4SpDkg+zbWHZBdSbsT4d4O3AO4//Tr0gyHvRN4B+UErlFNz1JZ1eJ3Z5WZr4XbDiZOAXtRdj7vj4jrMnPnFmUXIyAX42S1V1GO22wDPDrXnSezNXBYy5qTMbQSEbdSxkZfkplXNuuuysztx9syDYpFOBlqfbVIs3W+R5kckDPWb0i5RMMDOrR3eWaumbFuz8z8Toea96RMN967+XdzyrzyF7WoFawLyBMz8yfN+t2BraaHL0as2fvw12KZiB455SPlgcCZEfE5ynSxiZkKoGIRhhfWZ4txQDZnhniz8paI6NpjOykinjoQkI+lXAF011ELRcRKyjzy31Au9fBN4MhmGKOV5v99wiybVnP7S1mPovfhrxlDnrfbRIfO0ER8Q1BmnpzlBIgHUS6c9Wrg3hHx3oh4/Ly/LNVperbOqfQ3W+eSiHjBzJUR8TzKyVBd/A3lukVbR8STKGPcT2pZaxnlekc/B37CupO3WouIJRHxhog4OiIeH8UhlEvEPrtl2ffRTLUcGP76MOX1afWFyZm5WWYumeVnsy6faCdiaGU2EfEnlAvrPCcz9x13e6S+LcJsnftSpgPeQDm7MylfpLIJ5RLGP+nY3kdRLu16I7B/Zq7tUCsovfK9mp9dKGfNfisz571O0Bz1ep9RtRjDX4tlYoNcUjux7iJx06d/f6lDrZnfCrUz5YDir6D9t0IN1N+WMka+F+UyCvfKzM1b1Bmc1rchPcyoinIG6kMz8+aIuAxYkZlfnd6WE3Sm+aSMkUvqSZare7a+wucM7+ypzm0i4hWU4N6bMhPqG5Se9LHARS3LLsaMqsU4WW1R2COX9EcVEUfSzB2fPpDYQ81FmVHV9/DXYjHIJS0oer6MrfplkEtaUPR4GVv1byKmH0qaeP9piE8ue+SSFhQR76acRn4K3S9jq545a0XSMPq8jK16Zo9ckipnj1zSgiLibsBLKCca3Xblv8x88dgapdt4sFPSMD5KGSP/S+AsynXOJ/ISxusjh1YkLSgizs/M3ae/xSYi7gJ83usgTQZ75JKGMX0K/HURsQtwT2D5+JqjQY6RSxrGyojYAvg7yhdv3wN403ibpGkOrUhqJSK2yxZflKz+ObQiaV4R8aiIOCAitmqWd4uIjwFfH3PT1DDIJc0pIt5Bubzss4DTI+LNwBmUr2hr/R2g6pdDK5LmFBGXAHtk5o3NGPlPgd0y83tjbpoG2COXNJ8bMvNGgObLkS83xCePPXJJc4qI64CvDqx6zOBy1696Uz8McklziojHzrc9M8/6Y7VFczPIJalyjpFLUuUMckmqnEEuaWgRsem426A7MsglLSgi9mrmlF/aLD8kIt4z5mapYZBLGsZRlGuRXwuQmRdSpiJqAhjkkoaSmT+aseqWsTREd+BlbCUN40cRsReQEbEx8AqaYRaNn/PIJS0oIrYE3g3sBwTwBeCVmXntWBsmwCCXpOo5tCJpQRFxHHCHXl9mvngMzdEMBrmkYXx64PbdgGdQLmmrCeDQiqSRRcQGwBczc99xt0VOP5TUzgOAZeNuhAqHViQtKCJ+Qxkjj+bfnwOvG2ujdBuHViSpcvbIJc0pIvaYb3tmnvfHaovmZo9c0pwi4sx5NqcHOyeDQS5JlXNoRdJQImIXYGfKPHIAMvMj42uRptkjl7SgiHgz8OeUIP8M8ETg65l5wDjbpcJ55JKGcQDwOODnmfki4CHAXcfbJE0zyCUN44bMvBW4OSKWAL8Ath9zm9RwjFzSMFZFxObA+4Fzgd8C3x5ri3Qbx8glzSkijgY+lpnfHFi3HFiSmavH1jDdjj1ySfP5HvCuiNgG+ATw8cy8YLxN0kz2yCUtKCK2Aw5sfu4GfBw4ITOvGGvDBBjkkkYUEbsDxwK7ZeaG426PnLUiaQgRcZeIeEpEHA98FrgCeNaYm6WGPXJJc4qIvwCeC+xPmaVyAnBKZv5urA3T7RjkkubUXDTrY8BJmfnLcbdHszPIJalyjpFLUuUMckmqnEEuSZUzyCWpcga5JFXuvwE57wbQgZcL1AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Reg post tuning\n",
    "model = Pipeline([\n",
    "    (\"std\", StandardScaler()),\n",
    "    (\"logr\", LogisticRegression(penalty = 'none', solver = 'newton-cg', random_state=123))\n",
    "])\n",
    "model.fit(train[xcols], train[\"allstars\"])\n",
    "model.score(test[xcols], test[\"allstars\"])\n",
    "\n",
    "print(f\"Train Accuracy: {model.score(train[xcols], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {model.score(test[xcols], test['allstars'])*100:0.3f}%\")\n",
    "pd.Series(model[\"logr\"].coef_.reshape(-1), index=xcols).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamter tuning did not affect much for logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "70 fits failed out of a total of 160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.9304009  0.92994428 0.90749235 0.91207113 0.92765699 0.92811571\n",
      " 0.90749235 0.91207113        nan        nan 0.90795107        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Reg w alt features\n",
    "# Tuning hyperparameters for logistic regression\n",
    "\n",
    "model = LogisticRegression(random_state=3)\n",
    "params =  {\n",
    "    'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'saga', 'sag']\n",
    "}\n",
    "grid = GridSearchCV(estimator=model,\n",
    "                    param_grid=params,\n",
    "                    cv=10,\n",
    "                    n_jobs=1,\n",
    "                    verbose=0)\n",
    "grid.fit(train[xcols_alt], train['allstars'])\n",
    "p = grid.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 92.995%\n",
      "Valid Accuracy: 92.044%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Reg alt features post tuning\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"std\", StandardScaler()),\n",
    "    (\"logr\", LogisticRegression(penalty = p['penalty'], solver = p['solver'], random_state=4))\n",
    "])\n",
    "model.fit(train[xcols_alt], train[\"allstars\"])\n",
    "model.score(test[xcols_alt], test[\"allstars\"])\n",
    "\n",
    "print(f\"Train Accuracy: {model.score(train[xcols_alt], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {model.score(test[xcols_alt], test['allstars'])*100:0.3f}%\")\n",
    "pd.Series(model[\"logr\"].coef_.reshape(-1), index=xcols_alt).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86, 0.07, 0.03, 0.02, 0.01, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "df_pca = df[xcols].dropna()\n",
    "pca = PCA(n_components = 16, random_state=123)\n",
    "pca.fit(df_pca)\n",
    "key_df = pd.DataFrame(pca.components_)\n",
    "arr = pca.transform(df_pca)\n",
    "data_df = pd.DataFrame(arr)\n",
    "pca.explained_variance_ratio_.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.857, 0.073, 0.03 , 0.017, 0.009, 0.008, 0.004])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.DataFrame(pca.fit_transform(df_pca))\n",
    "key_df = pd.DataFrame(pca.components_)\n",
    "pca = PCA(n_components = 7, random_state=123)\n",
    "data_df = pd.DataFrame(pca.fit_transform(df_pca))\n",
    "key_df = pd.DataFrame(pca.components_)\n",
    "pca.explained_variance_ratio_.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.857, 0.073, 0.03 , 0.017, 0.009, 0.008, 0.004])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components = 7, whiten = False, random_state=123)\n",
    "data_df = pd.DataFrame(pca.fit_transform(df_pca))\n",
    "key_df = pd.DataFrame(pca.components_)\n",
    "pca.explained_variance_ratio_.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_list = [1,2,3,4,5,6,7,8,9,10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     0.856697\n",
      "2     0.929486\n",
      "3     0.959513\n",
      "4     0.976102\n",
      "5     0.985542\n",
      "6     0.993477\n",
      "7     0.997180\n",
      "8     0.998789\n",
      "9     0.999860\n",
      "10    0.999988\n",
      "11    0.999999\n",
      "12    1.000000\n",
      "13    1.000000\n",
      "14    1.000000\n",
      "15    1.000000\n",
      "16    1.000000\n",
      "dtype: float64\n",
      "1     0.475408\n",
      "2     0.587524\n",
      "3     0.679086\n",
      "4     0.745657\n",
      "5     0.807989\n",
      "6     0.865296\n",
      "7     0.912900\n",
      "8     0.943769\n",
      "9     0.973368\n",
      "10    0.984398\n",
      "11    0.991165\n",
      "12    0.994479\n",
      "13    0.997612\n",
      "14    0.999396\n",
      "15    0.999979\n",
      "16    1.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def explained(scale):\n",
    "    stages = [(\"imp\", SimpleImputer(strategy=\"most_frequent\"))]\n",
    "    if scale:\n",
    "        stages.append((\"std\", StandardScaler()))\n",
    "    stages.append((\"pca\", PCA()))\n",
    "    p = Pipeline(stages)\n",
    "    p.fit(df[xcols])\n",
    "    #print(p[\"pca\"].components_.round(2))\n",
    "    explained = p[\"pca\"].explained_variance_\n",
    "    s = pd.Series(explained.cumsum() / explained.sum(),\n",
    "                  index=range(1, len(xcols)+1))\n",
    "    print(s)\n",
    "    return s\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "ax = explained(False).plot.line(label=\"not scaled\", ylim=0)\n",
    "explained(True).plot.line(label=\"scaled\", ax=ax)\n",
    "ax.set_xlabel(\"Number of Components\")\n",
    "ax.set_ylabel(\"Explained Variance\")\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.legend(frameon=False)\n",
    "ax.set_title(\"Figure 2: Cumulative Principal Components\", pad=20)\n",
    "\n",
    "plt.savefig(\"Fig 2.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 93.590%\n",
      "Valid Accuracy: 91.495%\n",
      "Alt Train Accuracy: 93.727%\n",
      "Alt Valid Accuracy: 90.947%\n"
     ]
    }
   ],
   "source": [
    "# Knn\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train[xcols], train[\"allstars\"])\n",
    "print(f\"Train Accuracy: {knn.score(train[xcols], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {knn.score(test[xcols], test['allstars'])*100:0.3f}%\")\n",
    "knn.fit(train[xcols_alt], train[\"allstars\"])\n",
    "print(f\"Alt Train Accuracy: {knn.score(train[xcols_alt], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Alt Valid Accuracy: {knn.score(test[xcols_alt], test['allstars'])*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 566, in _fit\n",
      "    raise ValueError(\"Expected n_neighbors > 0. Got %d\" % self.n_neighbors)\n",
      "ValueError: Expected n_neighbors > 0. Got 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.92214402 0.92306983 0.9249026  0.9249047  0.92719199\n",
      " 0.92582213 0.92673746 0.9221545  0.92673327 0.92353274 0.92307402\n",
      " 0.9226195  0.9226174  0.9226174  0.9226195  0.92170416 0.92399145\n",
      " 0.9203322  0.92124754]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 25}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Knn tuning\n",
    "\n",
    "# Tuning hyperparametres for knn\n",
    "\n",
    "n_neigh_list = []\n",
    "for i in range(20):\n",
    "    n_neigh_list.append(i*5)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "params =  {\n",
    "    'n_neighbors': n_neigh_list,\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=knn,\n",
    "                    param_grid=params,\n",
    "                    cv=10,\n",
    "                    n_jobs=1,\n",
    "                    verbose=1)\n",
    "\n",
    "grid.fit(train[xcols], train['allstars'])\n",
    "\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 92.995%\n",
      "Valid Accuracy: 91.358%\n",
      "Alt Train Accuracy: 93.132%\n",
      "Alt Valid Accuracy: 91.221%\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=25)\n",
    "knn.fit(train[xcols], train[\"allstars\"])\n",
    "print(f\"Train Accuracy: {knn.score(train[xcols], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {knn.score(test[xcols], test['allstars'])*100:0.3f}%\")\n",
    "knn.fit(train[xcols_alt], train[\"allstars\"])\n",
    "print(f\"Alt Train Accuracy: {knn.score(train[xcols_alt], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Alt Valid Accuracy: {knn.score(test[xcols_alt], test['allstars'])*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 99.542%\n",
      "Valid Accuracy: 92.318%\n",
      "Alt Train Accuracy: 99.313%\n",
      "Alt Valid Accuracy: 92.455%\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=12, random_state=0, n_estimators = 100, criterion = \"gini\", bootstrap = True, min_samples_split = 4, max_features = \"sqrt\")\n",
    "clf.fit(train[xcols], train[\"allstars\"])\n",
    "print(f\"Train Accuracy: {clf.score(train[xcols], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {clf.score(test[xcols], test['allstars'])*100:0.3f}%\")\n",
    "clf.fit(train[xcols_alt], train[\"allstars\"])\n",
    "print(f\"Alt Train Accuracy: {clf.score(train[xcols_alt], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Alt Valid Accuracy: {clf.score(test[xcols_alt], test['allstars'])*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "Train Accuracy: 94.093%\n",
      "Valid Accuracy: 92.181%\n"
     ]
    }
   ],
   "source": [
    "# Grid search for best params for Random Forest\n",
    "clf = RandomForestClassifier(random_state=123)\n",
    "\n",
    "\n",
    "params =  {\n",
    "    'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 24],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf,\n",
    "                    param_grid=params,\n",
    "                    cv=10,\n",
    "                    n_jobs=1,\n",
    "                    verbose=1)\n",
    "\n",
    "grid.fit(train[xcols], train['allstars'])\n",
    "\n",
    "# Decision Tree with grid search params\n",
    "\n",
    "clf = RandomForestClassifier(max_depth = grid.best_params_['max_depth'],\n",
    "#                             max_features = grid.best_params_['max_features'],\n",
    "#                             min_samples_split = grid.best_params_['min_samples_split'], \n",
    "                            criterion = grid.best_params_['criterion'],\n",
    "                            random_state=123)\n",
    "clf.fit(train[xcols], train[\"allstars\"])\n",
    "print(f\"Train Accuracy: {clf.score(train[xcols], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {clf.score(test[xcols], test['allstars'])*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 99.908%\n",
      "Valid Accuracy: 90.123%\n",
      "Alt Train Accuracy: 98.901%\n",
      "Alt Valid Accuracy: 89.575%\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=12, max_features = \"auto\", random_state=123)\n",
    "dtc.fit(train[xcols], train[\"allstars\"])\n",
    "print(f\"Train Accuracy: {dtc.score(train[xcols], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {dtc.score(test[xcols], test['allstars'])*100:0.3f}%\")\n",
    "dtc.fit(train[xcols_alt], train[\"allstars\"])\n",
    "print(f\"Alt Train Accuracy: {dtc.score(train[xcols_alt], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Alt Valid Accuracy: {dtc.score(test[xcols_alt], test['allstars'])*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 320 candidates, totalling 3200 fits\n",
      "Train Accuracy: 92.811%\n",
      "Valid Accuracy: 91.770%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\edmo2\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "800 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "800 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\edmo2\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\edmo2\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\users\\edmo2\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\users\\edmo2\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.92214612 0.92214612 0.92214612        nan 0.92214612\n",
      " 0.92214612 0.92214612        nan 0.92214612 0.92214612 0.92214612\n",
      "        nan 0.92444389 0.92444389 0.92444389        nan 0.91940639\n",
      " 0.91940639 0.91940639        nan 0.91940639 0.91940639 0.91940639\n",
      "        nan 0.91940639 0.91940639 0.91940639        nan 0.91757153\n",
      " 0.91757153 0.91757153        nan 0.9143668  0.91344728 0.91207323\n",
      "        nan 0.9143668  0.91344728 0.91207323        nan 0.9143668\n",
      " 0.91344728 0.91207323        nan 0.9043002  0.90429391 0.90612878\n",
      "        nan 0.9093356  0.91298647 0.90567006        nan 0.9093356\n",
      " 0.91298647 0.90567006        nan 0.9093356  0.91298647 0.90567006\n",
      "        nan 0.89376231 0.88964015 0.89330778        nan 0.89650203\n",
      " 0.89605379 0.90383939        nan 0.89650203 0.89605379 0.90383939\n",
      "        nan 0.89650203 0.89605379 0.90383939        nan 0.88735914\n",
      " 0.88964643 0.89331197        nan 0.89101839 0.90108709 0.8946923\n",
      "        nan 0.89101839 0.90108709 0.8946923         nan 0.89101839\n",
      " 0.90108709 0.8946923         nan 0.88414394 0.87819949 0.88598509\n",
      "        nan 0.89834946 0.89696913 0.89513007        nan 0.89834946\n",
      " 0.89696913 0.89513007        nan 0.89834946 0.89696913 0.89513007\n",
      "        nan 0.88643961 0.87866239 0.88231955        nan 0.88689623\n",
      " 0.89696703 0.89971095        nan 0.88689623 0.89696703 0.89971095\n",
      "        nan 0.88689623 0.89696703 0.89971095        nan 0.88461103\n",
      " 0.87774496 0.88278036        nan 0.88735914 0.89559088 0.89559298\n",
      "        nan 0.88735914 0.89559088 0.89559298        nan 0.88735914\n",
      " 0.89559088 0.89559298        nan 0.88461103 0.87728625 0.88278036\n",
      "        nan 0.88735914 0.89559088 0.89559298        nan 0.88735914\n",
      " 0.89559088 0.89559298        nan 0.88735914 0.89559088 0.89559298\n",
      "        nan 0.88461103 0.87728625 0.88278036        nan 0.90887897\n",
      " 0.90887897 0.90887897        nan 0.90887897 0.90887897 0.90887897\n",
      "        nan 0.90887897 0.90887897 0.90887897        nan 0.9125466\n",
      " 0.9125466  0.9125466         nan 0.92216916 0.92216916 0.92216916\n",
      "        nan 0.92216916 0.92216916 0.92216916        nan 0.92216916\n",
      " 0.92216916 0.92216916        nan 0.92078673 0.92078673 0.92078673\n",
      "        nan 0.91161451 0.91298647 0.91162498        nan 0.91161451\n",
      " 0.91298647 0.91162498        nan 0.91161451 0.91298647 0.91162498\n",
      "        nan 0.90108709 0.90108709 0.89971304        nan 0.90932931\n",
      " 0.90796573 0.90247162        nan 0.90932931 0.90796573 0.90247162\n",
      "        nan 0.90932931 0.90796573 0.90247162        nan 0.89239663\n",
      " 0.89285535 0.89514893        nan 0.89927318 0.90339114 0.89651041\n",
      "        nan 0.89927318 0.90339114 0.89651041        nan 0.89927318\n",
      " 0.90339114 0.89651041        nan 0.88553684 0.88874995 0.88920238\n",
      "        nan 0.8983348  0.89787399 0.89559298        nan 0.8983348\n",
      " 0.89787399 0.89559298        nan 0.8983348  0.89787399 0.89559298\n",
      "        nan 0.89011143 0.88827657 0.88964853        nan 0.89057015\n",
      " 0.89421683 0.90477148        nan 0.89057015 0.89421683 0.90477148\n",
      "        nan 0.89057015 0.89421683 0.90477148        nan 0.88874157\n",
      " 0.88828076 0.88644171        nan 0.88645009 0.88690252 0.89423149\n",
      "        nan 0.88645009 0.88690252 0.89423149        nan 0.88645009\n",
      " 0.88690252 0.89423149        nan 0.88644799 0.88553265 0.88735704\n",
      "        nan 0.88234888 0.88782414 0.89285535        nan 0.88234888\n",
      " 0.88782414 0.89285535        nan 0.88234888 0.88782414 0.89285535\n",
      "        nan 0.88690671 0.88553265 0.88506766        nan 0.88234888\n",
      " 0.88782414 0.89285535        nan 0.88234888 0.88782414 0.89285535\n",
      "        nan 0.88234888 0.88782414 0.89285535        nan 0.88690671\n",
      " 0.88553265 0.88506766]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for best params\n",
    "dtc = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "params =  {\n",
    "    'min_samples_split': [1, 2, 3, 4],\n",
    "    'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 24, None],\n",
    "    'max_features': [\"auto\",\"sqrt\", \"log2\", None],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=dtc,\n",
    "                    param_grid=params,\n",
    "                    cv=10,\n",
    "                    n_jobs=1,\n",
    "                    verbose=1)\n",
    "\n",
    "grid.fit(train[xcols], train['allstars'])\n",
    "\n",
    "# Decision Tree with grid search params\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth = grid.best_params_['max_depth'],\n",
    "                             max_features = grid.best_params_['max_features'],\n",
    "                             min_samples_split = grid.best_params_['min_samples_split'], \n",
    "                             criterion = grid.best_params_['criterion'])\n",
    "dtc.fit(train[xcols], train[\"allstars\"])\n",
    "print(f\"Train Accuracy: {dtc.score(train[xcols], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {dtc.score(test[xcols], test['allstars'])*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 320 candidates, totalling 3200 fits\n",
      "Train Accuracy: 92.811%\n",
      "Valid Accuracy: 91.770%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "800 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "800 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\users\\olson\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.9148339  0.9148339  0.9148339         nan 0.9148339\n",
      " 0.9148339  0.9148339         nan 0.9148339  0.9148339  0.9148339\n",
      "        nan 0.92444389 0.92444389 0.92444389        nan 0.91987558\n",
      " 0.91987558 0.91987558        nan 0.91987558 0.91987558 0.91987558\n",
      "        nan 0.91987558 0.91987558 0.91987558        nan 0.92124754\n",
      " 0.92124754 0.92124754        nan 0.91941477 0.9148339  0.91575552\n",
      "        nan 0.91941477 0.9148339  0.91575552        nan 0.91941477\n",
      " 0.9148339  0.91575552        nan 0.90476729 0.90613715 0.90796783\n",
      "        nan 0.90843702 0.90703992 0.90753215        nan 0.90843702\n",
      " 0.90703992 0.90753215        nan 0.90843702 0.90703992 0.90753215\n",
      "        nan 0.90248    0.902015   0.90201081        nan 0.89789284\n",
      " 0.90155    0.89835575        nan 0.89789284 0.90155    0.89835575\n",
      "        nan 0.89789284 0.90155    0.89835575        nan 0.89926689\n",
      " 0.90109128 0.90155209        nan 0.89881237 0.90980897 0.89699007\n",
      "        nan 0.89881237 0.90980897 0.89699007        nan 0.89881237\n",
      " 0.90980897 0.89699007        nan 0.89652507 0.89606426 0.8955867\n",
      "        nan 0.89468393 0.89468812 0.90155209        nan 0.89468393\n",
      " 0.89468812 0.90155209        nan 0.89468393 0.89468812 0.90155209\n",
      "        nan 0.89789703 0.89653345 0.89606007        nan 0.88367894\n",
      " 0.89606426 0.90842445        nan 0.88367894 0.89606426 0.90842445\n",
      "        nan 0.88367894 0.89606426 0.90842445        nan 0.89881237\n",
      " 0.89423778 0.89606007        nan 0.88413766 0.89514893 0.90018013\n",
      "        nan 0.88413766 0.89514893 0.90018013        nan 0.88413766\n",
      " 0.89514893 0.90018013        nan 0.90018851 0.89515521 0.89606007\n",
      "        nan 0.88413766 0.89514893 0.90018013        nan 0.88413766\n",
      " 0.89514893 0.90018013        nan 0.88413766 0.89514893 0.90018013\n",
      "        nan 0.90018851 0.89515521 0.89606007        nan 0.90614553\n",
      " 0.90614553 0.90614553        nan 0.90614553 0.90614553 0.90614553\n",
      "        nan 0.90614553 0.90614553 0.90614553        nan 0.9125466\n",
      " 0.9125466  0.9125466         nan 0.91666876 0.91666876 0.91666876\n",
      "        nan 0.91666876 0.91666876 0.91666876        nan 0.91666876\n",
      " 0.91666876 0.91666876        nan 0.92124754 0.92124754 0.92124754\n",
      "        nan 0.91758619 0.92032173 0.91757362        nan 0.91758619\n",
      " 0.92032173 0.91757362        nan 0.91758619 0.92032173 0.91757362\n",
      "        nan 0.91300323 0.91300323 0.91345985        nan 0.90337648\n",
      " 0.90613087 0.90796364        nan 0.90337648 0.90613087 0.90796364\n",
      "        nan 0.90337648 0.90613087 0.90796364        nan 0.90567844\n",
      " 0.90613715 0.90568053        nan 0.8992648  0.9061183  0.9088706\n",
      "        nan 0.8992648  0.9061183  0.9088706         nan 0.8992648\n",
      " 0.9061183  0.9088706         nan 0.90660006 0.90614344 0.90613506\n",
      "        nan 0.88783252 0.88827657 0.9015479         nan 0.88783252\n",
      " 0.88827657 0.9015479         nan 0.88783252 0.88827657 0.9015479\n",
      "        nan 0.90156466 0.90156047 0.90201919        nan 0.88645637\n",
      " 0.89194001 0.89789075        nan 0.88645637 0.89194001 0.89789075\n",
      "        nan 0.88645637 0.89194001 0.89789075        nan 0.89743831\n",
      " 0.89927108 0.89926899        nan 0.88599346 0.89469859 0.89286792\n",
      "        nan 0.88599346 0.89469859 0.89286792        nan 0.88599346\n",
      " 0.89469859 0.89286792        nan 0.89972351 0.89788865 0.89698169\n",
      "        nan 0.88508232 0.88873529 0.89196096        nan 0.88508232\n",
      " 0.88873529 0.89196096        nan 0.88508232 0.88873529 0.89196096\n",
      "        nan 0.89789284 0.89926061 0.89835365        nan 0.88508232\n",
      " 0.89057015 0.89196096        nan 0.88508232 0.89057015 0.89196096\n",
      "        nan 0.88508232 0.89057015 0.89196096        nan 0.89789284\n",
      " 0.89926061 0.89835365]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for best params w alt features\n",
    "dtc = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "params =  {\n",
    "    'min_samples_split': [1, 2, 3, 4],\n",
    "    'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 24, None],\n",
    "    'max_features': [\"auto\",\"sqrt\", \"log2\", None],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=dtc,\n",
    "                    param_grid=params,\n",
    "                    cv=10,\n",
    "                    n_jobs=1,\n",
    "                    verbose=1)\n",
    "\n",
    "grid.fit(train[xcols_alt], train['allstars'])\n",
    "\n",
    "# Decision Tree with grid search params w alt features\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth = grid.best_params_['max_depth'],\n",
    "                             max_features = grid.best_params_['max_features'],\n",
    "                             min_samples_split = grid.best_params_['min_samples_split'], \n",
    "                             criterion = grid.best_params_['criterion'])\n",
    "dtc.fit(train[xcols_alt], train[\"allstars\"])\n",
    "print(f\"Train Accuracy: {dtc.score(train[xcols_alt], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {dtc.score(test[xcols_alt], test['allstars'])*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 2,\n",
       " 'max_features': None,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 92.399%\n",
      "Valid Accuracy: 90.535%\n",
      "Alt Train Accuracy: 92.766%\n",
      "Alt Valid Accuracy: 90.535%\n"
     ]
    }
   ],
   "source": [
    "# MLP\n",
    "\n",
    "mlp = MLPClassifier(random_state=123, max_iter = 300)\n",
    "mlp.fit(train[xcols], train[\"allstars\"])\n",
    "print(f\"Train Accuracy: {mlp.score(train[xcols], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {mlp.score(test[xcols], test['allstars'])*100:0.3f}%\")\n",
    "mlp.fit(train[xcols_alt], train[\"allstars\"])\n",
    "print(f\"Alt Train Accuracy: {mlp.score(train[xcols_alt], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Alt Valid Accuracy: {mlp.score(test[xcols_alt], test['allstars'])*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 93.956%\n",
      "Valid Accuracy: 91.907%\n",
      "Alt Train Accuracy: 93.452%\n",
      "Alt Valid Accuracy: 91.632%\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "\n",
    "ada = AdaBoostClassifier(random_state=123)\n",
    "ada.fit(train[xcols], train[\"allstars\"])\n",
    "print(f\"Train Accuracy: {ada.score(train[xcols], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Valid Accuracy: {ada.score(test[xcols], test['allstars'])*100:0.3f}%\")\n",
    "ada.fit(train[xcols_alt], train[\"allstars\"])\n",
    "print(f\"Alt Train Accuracy: {ada.score(train[xcols_alt], train['allstars'])*100:0.3f}%\")\n",
    "print(f\"Alt Valid Accuracy: {ada.score(test[xcols_alt], test['allstars'])*100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_objective(trial, X_train, y_train, cv=5):\n",
    "\n",
    "    \n",
    "    params =  {\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_impurity_decrease': trial.suggest_uniform('min_impurity_decrease', 0.0, 0.5),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [6, 16, None])\n",
    "    }\n",
    "\n",
    "    cv_iterator = StratifiedKFold(n_splits=cv, shuffle=True, random_state=123)\n",
    "\n",
    "    cv_scores = np.zeros(cv)\n",
    "    for idx, (train_sub_idx, valid_idx) in enumerate(cv_iterator.split(X_train, y_train)):\n",
    "        \n",
    "        X_train_sub, X_valid = X_train[train_sub_idx], X_train[valid_idx]\n",
    "        y_train_sub, y_valid = y_train[train_sub_idx], y_train[valid_idx]\n",
    "        \n",
    "\n",
    "        model = DecisionTreeClassifier(**params, random_state=123)\n",
    "        model.fit(X_train_sub, y_train_sub)\n",
    "        preds = model.score(X_valid, y_valid)\n",
    "        \n",
    "        cv_scores[idx] = preds\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
